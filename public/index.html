<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=no" />
  <title>Head Tracker + Notion Tasks (Demo)</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div id="app">
    <video id="video" autoplay playsinline muted></video>
    <div id="overlay"></div>
    <div id="controls">
      <button id="btnStart">Start Camera</button>
      <label>Max faces:
        <select id="maxFaces">
          <option value="1">1</option>
          <option value="2">2</option>
          <option value="3">3</option>
          <option value="4">4</option>
          <option value="5" selected>5</option>
        </select>
      </label>
      <span id="status">Idle</span>
    </div>
  </div>

  <script type="module">
    import { FaceMesh } from "https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js";
    import { Camera } from "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js";

    const video = document.getElementById("video");
    const overlay = document.getElementById("overlay");
    const btnStart = document.getElementById("btnStart");
    const statusText = document.getElementById("status");
    const maxFacesSelect = document.getElementById("maxFaces");

    let camera;
    let faceMesh;
    let tasks = [];
    let pollingInterval = 3000; // ms

    async function fetchTasks() {
      try {
        const res = await fetch("/tasks");
        const json = await res.json();
        tasks = (json.items || []);
      } catch (e) {
        console.warn("Failed to load tasks:", e);
      }
    }

    // initial load
    fetchTasks();
    setInterval(fetchTasks, pollingInterval);

    function clearBalloons() {
      overlay.innerHTML = "";
    }

    function createBalloon(xPx, yPx, text, id) {
      const el = document.createElement("div");
      el.className = "balloon";
      el.style.left = `${xPx}px`;
      el.style.top = `${yPx}px`;
      el.innerHTML = `<strong>${text.name}</strong><div class="task">${text.task}</div><div class="status">${text.status}</div>`;
      el.dataset.personIndex = id;
      overlay.appendChild(el);
    }

    function onResults(results) {
      overlay.innerHTML = ""; // clear and redraw
      const faces = results.multiFaceLandmarks || [];
      const maxFaces = Math.min(parseInt(maxFacesSelect.value || "5", 10), 5);
      const count = Math.min(faces.length, maxFaces);

      for (let i = 0; i < count; i++) {
        const lm = faces[i];
        // landmark 1 is near nose tip - use as head center
        const nose = lm[1];
        // video might be mirrored depending on camera; use bounding calculations from video size
        const vw = video.videoWidth || video.clientWidth;
        const vh = video.videoHeight || video.clientHeight;

        // MediaPipe x,y are normalized [0..1] based on the input image. Map to page coords.
        const x = nose.x * vw;
        const y = nose.y * vh;

        // get corresponding Notion person data by index (simple mapping)
        const person = tasks[i % (tasks.length || 1)] || { name: "No data", task: "", status: "" };

        // translate video coords to overlay (video may be scaled to CSS size)
        // compute bounding rect to map video pixels to page pixels
        const rect = video.getBoundingClientRect();
        const scaleX = rect.width / vw;
        const scaleY = rect.height / vh;
        const pageX = rect.left + x * scaleX;
        const pageY = rect.top + y * scaleY - 70; // offset above head

        createBalloon(pageX, pageY, person, i);
      }

      statusText.textContent = `Faces: ${faces.length} | Tasks: ${tasks.length}`;
    }

    btnStart.addEventListener("click", async () => {
      btnStart.disabled = true;
      statusText.textContent = "Requesting cameraâ€¦";
      faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });

      faceMesh.setOptions({
        maxNumFaces: parseInt(maxFacesSelect.value || "5", 10),
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });

      faceMesh.onResults(onResults);

      camera = new Camera(video, {
        onFrame: async () => {
          await faceMesh.send({ image: video });
        },
        width: 1280,
        height: 720
      });

      try {
        await camera.start();
        statusText.textContent = "Camera running";
      } catch (e) {
        console.error(e);
        statusText.textContent = "Camera error";
      }
    });
  </script>
</body>
</html>
